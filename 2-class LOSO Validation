import os
import cv2
import re
import random
import pandas as pd
import numpy as np
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import cycle

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import torchvision.transforms as transforms
    from torch.utils.data import DataLoader, TensorDataset
    from torchvision.models import alexnet, vgg11, googlenet, resnet18, resnet34, resnet50
    print(f"PyTorch version: {torch.__version__}")
except ImportError as e:
    print(f"Error importing PyTorch: {e}")
    print("Please ensure PyTorch and torchvision are installed correctly")
    exit(1)
except AttributeError as e:
    print(f"PyTorch import error: {e}")
    print("Attempting to clean and re-import...")
    import sys
    # Clean conflicting modules
    for mod in ['torch', 'torchvision']:
        if mod in sys.modules:
            del sys.modules[mod]
    import torch
    import torch.nn as nn
    import torch.optim as optim
    import torchvision.transforms as transforms
    from torch.utils.data import DataLoader, TensorDataset
    from torchvision.models import alexnet, vgg11, googlenet, resnet18, resnet34, resnet50
from sklearn.metrics import (classification_report, accuracy_score, confusion_matrix, f1_score,
                             roc_curve, auc, precision_recall_curve, precision_recall_fscore_support)
from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize
from sklearn.utils.multiclass import unique_labels
from imblearn.over_sampling import SMOTE

SEED = 42
def seed_everything(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.backends.cudnn.deterministic = True

seed_everything(SEED)

NUMERIC_FEATURES_PATH = r"D:\25shujia\features_all_label.xlsx"
TRAJECTORY_ROOT = r"D:\25shujia\qianceguijitu"
HEATMAP_ROOT = r"D:\25shujia\hotimg\img_yuanshi"
LABEL_DATA_PATH = r"D:\25shujia\data.xlsx"
SAVE_DIR = r".\result"
os.makedirs(SAVE_DIR, exist_ok=True)
CONFUSION_MATRIX_PATH = os.path.join(SAVE_DIR, "loocv_confusion_matrix.png")

D_MODEL = 64
N_HEADS = 2
BASE_LR = 0.0002
CNN_LR = 0.0002
NUM_EPOCHS = 50 
BATCH_SIZE = 8
SAMPLE_SEQUENCES = [1, 2, 3, 4]

class EfficientNetLite0(nn.Module):
    def __init__(self):
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(3, 32, 3, 2, 1, bias=False),
            nn.BatchNorm2d(32),
            nn.ReLU6(inplace=True)
        )
        self.middle = nn.Sequential(
            nn.Conv2d(32, 32, 3, 1, 1, groups=32, bias=False),
            nn.BatchNorm2d(32),
            nn.ReLU6(inplace=True),
            nn.Conv2d(32, 128, 1, bias=False),
            nn.BatchNorm2d(128)
        )
        self.head = nn.Sequential(
            nn.Conv2d(128, 1280, 1, bias=False),
            nn.BatchNorm2d(1280),
            nn.ReLU6(inplace=True)
        )
        self.avg_pool = nn.AdaptiveAvgPool2d(1)

    def forward(self, x):
        x = self.stem(x)
        x = self.middle(x)
        x = self.head(x)
        x = self.avg_pool(x)
        return x.view(x.size(0), -1)

class SMOTEFusionModel(nn.Module):
    def __init__(self, img_feat_dim, num_feat_dim, output_dim, d_model=D_MODEL):
        super().__init__()
        self.traj_proj = nn.Linear(img_feat_dim, d_model)
        self.heat_proj = nn.Linear(img_feat_dim, d_model)
        self.num_proj = nn.Sequential(nn.Linear(num_feat_dim, d_model), nn.LayerNorm(d_model), nn.ReLU())
        self.pos_encoding = nn.Parameter(torch.randn(1, 3, d_model))  # [1, 3, d_model]
        self.cross_attn_traj_heat = nn.MultiheadAttention(d_model, N_HEADS, batch_first=True, dropout=0.2)
        self.cross_attn_heat_traj = nn.MultiheadAttention(d_model, N_HEADS, batch_first=True, dropout=0.2)
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model, N_HEADS, 512, 0.3, batch_first=True), 3
        )
        self.modal_attention = nn.Sequential(
            nn.Linear(d_model * 3, d_model),
            nn.ReLU(),
            nn.LayerNorm(d_model),
            nn.Linear(d_model, 3),
            nn.Softmax(dim=1)
        
        self.residual_alpha = nn.Parameter(torch.tensor(0.5))
        self.deep_classifier = nn.Sequential(
            nn.Linear(d_model, d_model * 2),
            nn.BatchNorm1d(d_model * 2),
            nn.GELU(),
            nn.Dropout(0.3),

            nn.Linear(d_model * 2, d_model),
            nn.BatchNorm1d(d_model),
            nn.GELU(),
            nn.Dropout(0.3),

            nn.Linear(d_model, d_model // 2),
            nn.BatchNorm1d(d_model // 2),
            nn.GELU(),
            nn.Dropout(0.2),
        )
        self.feat_projection = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.BatchNorm1d(d_model // 2),
            nn.ReLU()
        )
        self.classifier_final = nn.Linear(d_model // 2, output_dim)
        self.residual_scale = nn.Parameter(torch.tensor(0.1))

    def forward(self, traj, heat, num):
        t_emb = self.traj_proj(traj) + self.pos_encoding  # [B, 3, d_model]
        h_emb = self.heat_proj(heat) + self.pos_encoding  # [B, 3, d_model]
        n_emb = self.num_proj(num).unsqueeze(1).repeat(1, 3, 1)  # [B, 3, d_model]
        t_h_inter, _ = self.cross_attn_traj_heat(t_emb, h_emb, h_emb)
        h_t_inter, _ = self.cross_attn_heat_traj(h_emb, t_emb, t_emb)
        fusion_emb = torch.cat([t_h_inter, h_t_inter, n_emb], dim=1)  # [B, 9, d_model]
        trans_feat = self.transformer(fusion_emb)                     # [B, 9, d_model]
        t_trans = trans_feat[:, 0:3, :] 
        h_trans = trans_feat[:, 3:6, :]  
        n_trans = trans_feat[:, 6:9, :]  

        alpha = torch.sigmoid(self.residual_alpha)

        t_global_orig = t_emb.mean(dim=1) 
        t_global_trans = t_trans.mean(dim=1)
        t_enhanced = alpha * t_global_trans + (1 - alpha) * t_global_orig

        h_global_orig = h_emb.mean(dim=1)      
        h_global_trans = h_trans.mean(dim=1)
        h_enhanced = alpha * h_global_trans + (1 - alpha) * h_global_orig

        n_global_orig = n_emb.mean(dim=1)
        n_global_trans = n_trans.mean(dim=1)   
        n_enhanced = alpha * n_global_trans + (1 - alpha) * n_global_orig

        modal_cat = torch.cat([t_enhanced, h_enhanced, n_enhanced], dim=1) 
        modal_weights = self.modal_attention(modal_cat)          

        fused_feat = (modal_weights[:, 0:1] * t_enhanced) + \
                     (modal_weights[:, 1:2] * h_enhanced) + \
                     (modal_weights[:, 2:3] * n_enhanced)  # [B, d_model]

        deep_features = self.deep_classifier(fused_feat)  # [B, d_model//2 = 32]
        fused_feat_proj = self.feat_projection(fused_feat)  # [B, d_model//2 = 32]

        residual_scale = torch.sigmoid(self.residual_scale)
        final_features = deep_features + residual_scale * fused_feat_proj

        logits = self.classifier_final(final_features)
        return logits, torch.softmax(logits, dim=1)

def get_paradigm_features(images, extractor):
    if len(images) == 0: return np.zeros(1280, dtype=np.float32)
    preprocess = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    tensors = torch.stack([preprocess(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) for img in images]).to(device)
    with torch.no_grad():
        return extractor(tensors).cpu().numpy().mean(axis=0)

def load_images_by_paradigm_and_sequence(root_dir, recording):
    PARADIGMS = {"paradigm1": "YANSHEN+TOU+SHOU", "paradigm2": "YANSHEN+TOU", "paradigm3": "YANSHEN"}
    data = {seq: {p: [] for p in PARADIGMS.keys()} for seq in SAMPLE_SEQUENCES}
    path = os.path.join(root_dir, recording)
    if os.path.exists(path):
        for f in os.listdir(path):
            m = re.search(r'([1-4])', f)
            s_num = int(m.group(1)) if m else None
            if s_num in SAMPLE_SEQUENCES:
                img = cv2.imread(os.path.join(path, f))
                if img is not None:
                    for p_n, p_k in PARADIGMS.items():
                        if p_k in f: data[s_num][p_n].append(img)
    return data

def plot_confusion_matrix(y_true, y_pred, classes):
    """Visualize confusion matrix"""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title('Leave-One-Out Cross Validation - Multimodal ASD Classification Confusion Matrix (Binary)', fontsize=14)
    plt.ylabel('True Label', fontsize=12)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.tight_layout()
    plt.savefig(CONFUSION_MATRIX_PATH, dpi=300, bbox_inches='tight')
    plt.close()  # Close plot to release memory

def main_loocv():
    extractor = EfficientNetLite0().to(device)
    extractor.eval()

    labels_df = pd.read_excel(LABEL_DATA_PATH)
    original_labels_dict = {}
    for _, row in labels_df.iterrows():
        if pd.notna(row.iloc[3]):
            subj_id = str(row.iloc[0]).strip()
            original_label = int(row.iloc[3])
            # Binary label mapping: original 0→0, 1/2→1
            binary_label = 0 if original_label == 0 else 1
            original_labels_dict[subj_id] = binary_label

    if len(original_labels_dict) == 0:
        raise ValueError("No valid label data loaded, please check label file path and format")

    le = LabelEncoder()
    le.fit(list(original_labels_dict.values()))
    output_dim = len(le.classes_)  # output_dim=2 for binary classification
    class_names = [str(c) for c in le.classes_] 
    print(f"Number of classes: {output_dim}, Class names: {class_names}")
    print(f"Label mapping rule: Original 0→0, Original 1/2→1")

    num_df = pd.read_excel(NUMERIC_FEATURES_PATH).fillna(0)
    num_feat_dict = {}
    for _, row in num_df.iterrows():
        subj_id = str(row.iloc[0]).strip()
        num_feat_dict[subj_id] = row.iloc[2:11].values.astype(np.float32)
    valid_subjects = [s for s in original_labels_dict.keys() if s in num_feat_dict]
    if len(valid_subjects) == 0:
        raise ValueError("No subjects with both labels and numeric features found, check data matching")
    print(f"Number of valid subjects: {len(valid_subjects)}")

    subjects_data, groups = [], []
    print("Extracting features...")
    for subj_id in valid_subjects:
        t_imgs = load_images_by_paradigm_and_sequence(TRAJECTORY_ROOT, subj_id)
        h_imgs = load_images_by_paradigm_and_sequence(HEATMAP_ROOT, subj_id)
        label = le.transform([original_labels_dict[subj_id]])[0]

        for seq in SAMPLE_SEQUENCES:
            t_f = np.array([
                get_paradigm_features(t_imgs[seq][p], extractor) 
                for p in ["paradigm1", "paradigm2", "paradigm3"]
            ])
            h_f = np.array([
                get_paradigm_features(h_imgs[seq][p], extractor) 
                for p in ["paradigm1", "paradigm2", "paradigm3"]
            ])
            assert t_f.shape == (3, 1280), f"Trajectory feature dimension error: {t_f.shape}"
            assert h_f.shape == (3, 1280), f"Heatmap feature dimension error: {h_f.shape}"
            
            subjects_data.append({
                "traj": t_f, 
                "heat": h_f, 
                "num": num_feat_dict[subj_id], 
                "label": label
            })
            groups.append(subj_id)

    assert len(subjects_data) == len(groups), "Feature data and group data length mismatch"
    aug_array = np.array(subjects_data)
    y_all = np.array([d["label"] for d in subjects_data])
    groups = np.array(groups)
    print(f"Total samples (including sequences): {len(y_all)}")
    print(f"Binary label distribution: Class 0: {np.sum(y_all==0)} samples, Class 1: {np.sum(y_all==1)} samples")
    unique_subjects = np.unique(groups)
    num_subjects = len(unique_subjects)
    print(f"\nStarting Leave-One-Out Cross Validation, {num_subjects} subjects total, {num_subjects} validation rounds...")
    
    all_y_true, all_y_pred = [], []
    all_y_pred_probs = []
    fold_f1_scores = []
    for fold_idx, test_subject in enumerate(unique_subjects):
        print(f"\n>> LOOCV Round {fold_idx+1}/{num_subjects} - Test Subject: {test_subject}")
        test_idx = np.where(groups == test_subject)[0]
        train_idx = np.where(groups != test_subject)[0]
        if len(test_idx) == 0:
            print(f"Warning: No test data for subject {test_subject}, skipping this round")
            continue
        if len(train_idx) == 0:
            print(f"Warning: No train data for subject {test_subject}, skipping this round")
            continue
        train_traj = np.array([d["traj"] for d in aug_array[train_idx]]).reshape(len(train_idx), -1)
        train_heat = np.array([d["heat"] for d in aug_array[train_idx]]).reshape(len(train_idx), -1)
        train_nums = np.array([d["num"] for d in aug_array[train_idx]])
        train_y = y_all[train_idx]
        test_traj = np.array([d["traj"] for d in aug_array[test_idx]]).reshape(len(test_idx), -1)
        test_heat = np.array([d["heat"] for d in aug_array[test_idx]]).reshape(len(test_idx), -1)
        test_nums = np.array([d["num"] for d in aug_array[test_idx]])
        test_y = y_all[test_idx]
        if len(np.unique(train_y)) < 2:
            print(f"  Warning: Train set contains only single class, skipping SMOTE")
            res_traj, res_heat, res_nums, res_y = train_traj, train_heat, train_nums, train_y
        else:
            train_all_feat = np.concatenate([train_traj, train_heat, train_nums], axis=1)
            sm = SMOTE(random_state=SEED)
            res_feat, res_y = sm.fit_resample(train_all_feat, train_y)
            res_traj = res_feat[:, :3840].reshape(-1, 3, 1280)
            res_heat = res_feat[:, 3840:7680].reshape(-1, 3, 1280)
            res_nums = res_feat[:, 7680:]

        scaler = StandardScaler()
        res_nums_scaled = scaler.fit_transform(res_nums)
        test_nums_scaled = scaler.transform(test_nums)
        train_dataset = TensorDataset(
            torch.FloatTensor(res_traj), 
            torch.FloatTensor(res_heat),
            torch.FloatTensor(res_nums_scaled), 
            torch.LongTensor(res_y)
        )
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        model = SMOTEFusionModel(1280, 9, output_dim).to(device)
        optimizer = optim.AdamW([
            {'params': model.traj_proj.parameters(), 'lr': CNN_LR},
            {'params': model.heat_proj.parameters(), 'lr': CNN_LR},
            {'params': model.num_proj.parameters(), 'lr': BASE_LR},
            {'params': model.cross_attn_traj_heat.parameters(), 'lr': BASE_LR},
            {'params': model.cross_attn_heat_traj.parameters(), 'lr': BASE_LR},
            {'params': model.transformer.parameters(), 'lr': BASE_LR},
            {'params': model.modal_attention.parameters(), 'lr': BASE_LR},
            {'params': model.residual_alpha, 'lr': BASE_LR},          
            {'params': model.deep_classifier.parameters(), 'lr': BASE_LR},
            {'params': model.feat_projection.parameters(), 'lr': BASE_LR},
            {'params': model.classifier_final.parameters(), 'lr': BASE_LR},
            {'params': model.residual_scale, 'lr': BASE_LR},          
        ], weight_decay=1e-2)

        criterion = nn.CrossEntropyLoss()
        best_fold_f1 = -1
        best_fold_preds = np.zeros(len(test_y))
        best_fold_probs = np.zeros((len(test_y), output_dim))

        for epoch in range(NUM_EPOCHS):
            model.train()
            epoch_loss = 0.0
            batch_count = 0

            for bt, bh, bn, bl in train_loader:
                bt, bh, bn, bl = bt.to(device), bh.to(device), bn.to(device), bl.to(device)
                optimizer.zero_grad()
                logits, _ = model(bt, bh, bn)
                loss = criterion(logits, bl)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

                optimizer.step()
                epoch_loss += loss.item()
                batch_count += 1
            model.eval()
            with torch.no_grad():
                v_t = torch.FloatTensor(np.array([d["traj"] for d in aug_array[test_idx]])).to(device)
                v_h = torch.FloatTensor(np.array([d["heat"] for d in aug_array[test_idx]])).to(device)
                v_n = torch.FloatTensor(test_nums_scaled).to(device)
                logits, probs = model(v_t, v_h, v_n)
                preds = logits.argmax(1).cpu().numpy()
                probs_np = probs.cpu().numpy()
                assert len(preds) == len(test_y), f"Prediction length ({len(preds)}) mismatch with test set ({len(test_y)})"
                current_f1 = f1_score(test_y, preds, average='weighted', zero_division=0)
                if current_f1 > best_fold_f1:
                    best_fold_f1 = current_f1
                    best_fold_preds = preds.copy()
                    best_fold_probs = probs_np.copy()
        all_y_true.extend(test_y)
        all_y_pred.extend(best_fold_preds)
        all_y_pred_probs.extend(best_fold_probs)
        fold_f1_scores.append(best_fold_f1)
        print(f"  Round {fold_idx+1} Best Weighted F1: {best_fold_f1:.4f}")
        with torch.no_grad():
            alpha_value = torch.sigmoid(model.residual_alpha).item()
            scale_value = torch.sigmoid(model.residual_scale).item()
            print(f"  Round {fold_idx+1} Parameters: alpha={alpha_value:.4f}, scale={scale_value:.4f}")
    assert len(all_y_true) == len(all_y_pred), f"Final true label length ({len(all_y_true)}) mismatch with predictions ({len(all_y_pred)})"
    print(f"\nFinal collected samples: True labels={len(all_y_true)}, Predictions={len(all_y_pred)}")
    all_y_pred_probs = np.array(all_y_pred_probs)
    if all_y_pred_probs.shape[1] != output_dim:
        temp_probs = np.zeros((len(all_y_pred_probs), output_dim))
        temp_probs[:, :all_y_pred_probs.shape[1]] = all_y_pred_probs
        all_y_pred_probs = temp_probs
    plot_confusion_matrix(all_y_true, all_y_pred, class_names)
    print("\n" + "="*60)
    print(" ASD Classification - LOOCV Comprehensive Evaluation Report (Binary) ")
    print("="*60)
    print("\nDetailed Classification Report:")
    print(classification_report(all_y_true, all_y_pred, target_names=class_names, zero_division=0))
    overall_acc = accuracy_score(all_y_true, all_y_pred)
    weighted_f1 = f1_score(all_y_true, all_y_pred, average='weighted', zero_division=0)
    macro_f1 = f1_score(all_y_true, all_y_pred, average='macro', zero_division=0)
    print(f"\nKey Metrics:")
    print(f"Overall Accuracy: {overall_acc:.4f}")
    print(f"Weighted F1 Score: {weighted_f1:.4f}")
    print(f"Macro F1 Score: {macro_f1:.4f}")
    print(f"Mean Fold F1 Score: {np.mean(fold_f1_scores):.4f} (+/- {np.std(fold_f1_scores):.4f})"    
    print(f"\nConfusion matrix saved to: {CONFUSION_MATRIX_PATH}")

if __name__ == "__main__":
    main_loocv()
